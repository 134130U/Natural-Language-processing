{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "word_vectors Mbaye Babou.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/134130U/Natural-Language-processing/blob/master/word_vectors_Mbaye_Babou.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EHU8nxzjpEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io, sys\n",
        "import numpy as np\n",
        "from heapq import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQsz-mpBjpE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_vectors(filename):\n",
        "    fin = io.open(filename, 'r', encoding='utf-8', newline='\\n')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = np.asarray(list(map(float, tokens[1:])))\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTVzWm1AjpFK",
        "colab_type": "code",
        "colab": {},
        "outputId": "76086415-81ae-49c0-9e5c-2cb4ae9e54ad"
      },
      "source": [
        "# Loading word vectors\n",
        "\n",
        "print('')\n",
        "print(' ** Word vectors ** ')\n",
        "print('')\n",
        "\n",
        "word_vectors = load_vectors('wiki.en.vec')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ** Word vectors ** \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oTh3Z39jpFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## This function computes the cosine similarity between vectors u and v\n",
        "\n",
        "def cosine(u, v):\n",
        "    ## FILL CODE\n",
        "    num = u.dot(v)\n",
        "    den = np.linalg.norm(u)*np.linalg.norm(v)\n",
        "    return num/den\n",
        "\n",
        "## This function returns the word corresponding to \n",
        "## nearest neighbor vector of x\n",
        "## The list exclude_words can be used to exclude some\n",
        "## words from the nearest neighbors search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV8wVxxajpFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdSso6LGjpFi",
        "colab_type": "code",
        "colab": {},
        "outputId": "a5f2d29a-a563-4e88-9845-1ba321f837a5"
      },
      "source": [
        "# compute similarity between words\n",
        "\n",
        "print('similarity(apple, apples) = %.3f' %\n",
        "      cosine(word_vectors['apple'], word_vectors['apples']))\n",
        "print('similarity(apple, banana) = %.3f' %\n",
        "      cosine(word_vectors['apple'], word_vectors['banana']))\n",
        "print('similarity(apple, tiger) = %.3f' %\n",
        "      cosine(word_vectors['apple'], word_vectors['tiger']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similarity(apple, apples) = 0.637\n",
            "similarity(apple, banana) = 0.431\n",
            "similarity(apple, tiger) = 0.212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8At1kX-jpFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Functions for nearest neighbors\n",
        "\n",
        "def nearest_neighbor(x, word_vectors, exclude_words=[]):\n",
        "    best_score = -1.0\n",
        "    best_word = ''\n",
        "    ## FILL CODE\n",
        "    for word in word_vectors:\n",
        "        if word not in exclude_words:\n",
        "            score  = cosine(x,word_vectors[word])\n",
        "            if score >=best_score:\n",
        "                best_word = word\n",
        "                best_score = score\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    return best_word\n",
        "\n",
        "## This function return the words corresponding to the\n",
        "## K nearest neighbors of vector x.\n",
        "## You can use the functions heappush and heappop.\n",
        "\n",
        "def knn(x, vectors, k,exclude=[]):\n",
        "    \n",
        "    heap=[]\n",
        "    ## FILL CODE\n",
        "    for i in range(k):\n",
        "        best_w = nearest_neighbor(x, vectors,exclude)\n",
        "        #print(best_w)\n",
        "        scor = cosine(x,vectors[best_w])\n",
        "        exclude.append(best_w)\n",
        "        heap.append((scor , best_w))\n",
        "    return heap\n",
        "    #return [heappop(heap) for i in range(len(heap))][::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcrXi60djpFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "V2cMBm4ejpF2",
        "colab_type": "code",
        "colab": {},
        "outputId": "1a0ae3e8-7dc4-4349-b0c3-79dbe5177f8e"
      },
      "source": [
        "print('The nearest neighbor of cat is: ' +\n",
        "      nearest_neighbor(word_vectors['cat'], word_vectors, ['cat','cats']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nearest neighbor of cat is: dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u84V3tJdjpF8",
        "colab_type": "code",
        "colab": {},
        "outputId": "8b83f198-267b-4cea-b1fd-137604826ddb"
      },
      "source": [
        "# looking at nearest neighbors of a word\n",
        "\n",
        "print('The nearest neighbor of cat is: ' +\n",
        "      nearest_neighbor(word_vectors['cat'], word_vectors, ['cat','cats'] ))\n",
        "\n",
        "knn_cat = knn(word_vectors['cat'], word_vectors, 5,['cat','cats'] )\n",
        "print('')\n",
        "print('cat')\n",
        "print('--------------')\n",
        "for score, word in knn(word_vectors['cat'], word_vectors, 5,['cat','cats'] ):\n",
        "    print(word + '\\t%.3f' % score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nearest neighbor of cat is: dog\n",
            "\n",
            "cat\n",
            "--------------\n",
            "dog\t0.638\n",
            "pet\t0.573\n",
            "rabbit\t0.549\n",
            "dogs\t0.538\n",
            "pig\t0.458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIJ1tMFjjpGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analogy(a,b,c,word_vectors):\n",
        "    ## FILL CODE\n",
        "    a, b, c= a.lower(), b.lower(), c.lower () \n",
        "     \n",
        "    max_cosine_sim = -np.inf \n",
        "    best_word = None \n",
        "    # search for d in the whole word vector set \n",
        "    for w in word_vectors.keys():\n",
        "        # ignore input words \n",
        "        if w in [a, b, c]: \n",
        "            continue \n",
        "\n",
        "        cos_sim = cosine(word_vectors[b] - word_vectors[a], word_vectors[w] - word_vectors[c]) \n",
        "        if cos_sim> max_cosine_sim: \n",
        "            max_cosine_sim = cos_sim \n",
        "            # update word_d \n",
        "            best_word = w\n",
        "    return best_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhwjYcsSjpGQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "2c16fb38-671a-44a8-9e03-afa1cdef296b"
      },
      "source": [
        "# Word analogies\n",
        "\n",
        "print('')\n",
        "print('King - Man + Woman = ' + analogy('man', 'king', 'woman', word_vectors))\n",
        "print('france - paris + rome = ' + analogy('paris', 'france', 'rome', word_vectors))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "King - Man + Woman = queen\n",
            "france - paris + rome = italy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6-k3rqijpGY",
        "colab_type": "code",
        "colab": {},
        "outputId": "92c47405-304d-4f1a-ef62-d2e6d6acb2d6"
      },
      "source": [
        "## A word about biases in word vectors:\n",
        "\n",
        "print('')\n",
        "print('similarity(genius, man) = %.3f' %\n",
        "      cosine(word_vectors['man'], word_vectors['genius']))\n",
        "print('similarity(genius, woman) = %.3f' %\n",
        "      cosine(word_vectors['woman'], word_vectors['genius']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "similarity(genius, man) = 0.445\n",
            "similarity(genius, woman) = 0.325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZud7a5fjpGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Compute the association strength between:\n",
        "##   - a word w\n",
        "##   - two sets of attributes A and B\n",
        "\n",
        "def association_strength(w, A, B, vectors):\n",
        "    \n",
        "    ## FILL CODE\n",
        "    w_A = [cosine(word_vectors[w],word_vectors[a]) for a in A]\n",
        "    w_B = [cosine(word_vectors[w],word_vectors[b]) for b in B]\n",
        "    strength = (sum(w_A)/len(A))-(sum(w_B)/len(B))\n",
        "    return strength\n",
        "\n",
        "## Perform the word embedding association test between:\n",
        "##   - two sets of words X and Y\n",
        "##   - two sets of attributes A and B\n",
        "\n",
        "def weat(X, Y, A, B, vectors):\n",
        "    ## FILL CODE\n",
        "    x_AB = [association_strength(x,A,B, vectors) for x in X]\n",
        "    z_AB = [association_strength(z,A,B, vectors) for z in Y]\n",
        "    score = sum(x_AB)-sum(z_AB)\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkjw5o91jpGn",
        "colab_type": "code",
        "colab": {},
        "outputId": "a9d4ad47-cc42-4c82-895a-81fb0ee3364b"
      },
      "source": [
        "## Replicate one of the experiments from:\n",
        "##\n",
        "## Semantics derived automatically from language corpora contain human-like biases\n",
        "## Caliskan, Bryson, Narayanan (2017)\n",
        "\n",
        "career = ['executive', 'management', 'professional', 'corporation', \n",
        "          'salary', 'office', 'business', 'career']\n",
        "family = ['home', 'parents', 'children', 'family',\n",
        "          'cousins', 'marriage', 'wedding', 'relatives']\n",
        "male = ['john', 'paul', 'mike', 'kevin', 'steve', 'greg', 'jeff', 'bill']\n",
        "female = ['amy', 'joan', 'lisa', 'sarah', 'diana', 'kate', 'ann', 'donna']\n",
        "\n",
        "print('')\n",
        "print('Word embedding association test: %.3f' %\n",
        "      weat(career, family, male, female, word_vectors))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Word embedding association test: 0.847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u0A-7SnjpGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}